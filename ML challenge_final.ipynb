{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad69cc79-4bf9-4420-affd-d974547d885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5621b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/dimo/Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cefeede8-341b-486b-9af8-6c2908f36de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authorName</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b341b6938308a6d5f47edf490f6e46eae3835fa</td>\n",
       "      <td>Detecting linguistic idiosyncratic interests i...</td>\n",
       "      <td>3188285</td>\n",
       "      <td>Masoud Rouhizadeh</td>\n",
       "      <td>Children with autism spectrum disorder often e...</td>\n",
       "      <td>2014</td>\n",
       "      <td>CLPsych@ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c682727ee058aadbe9dbf838dcb036322818f588</td>\n",
       "      <td>Bigrams and BiLSTMs Two Neural Networks for Se...</td>\n",
       "      <td>2782720</td>\n",
       "      <td>Yuri Bizzoni</td>\n",
       "      <td>We present and compare two alternative deep ne...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fig-Lang@NAACL-HLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f9b5b32229a7245e43754430c0c88f8e7f0d8af</td>\n",
       "      <td>In Factuality: Efficient Integration of Releva...</td>\n",
       "      <td>144748442</td>\n",
       "      <td>Peter Vickers</td>\n",
       "      <td>Visual Question Answering (VQA) methods aim at...</td>\n",
       "      <td>2021</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9</td>\n",
       "      <td>Variational Graph Autoencoding as Cheap Superv...</td>\n",
       "      <td>46331602</td>\n",
       "      <td>Irene Li</td>\n",
       "      <td>Coreference resolution over semantic graphs li...</td>\n",
       "      <td>2022</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07588dd5d0252c7abc99b3834a81bf23741ead4b</td>\n",
       "      <td>LIMIT-BERT : Linguistics Informed Multi-Task BERT</td>\n",
       "      <td>30887404</td>\n",
       "      <td>Junru Zhou</td>\n",
       "      <td>In this paper, we present Linguistics Informed...</td>\n",
       "      <td>2019</td>\n",
       "      <td>FINDINGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  0b341b6938308a6d5f47edf490f6e46eae3835fa   \n",
       "1  c682727ee058aadbe9dbf838dcb036322818f588   \n",
       "2  0f9b5b32229a7245e43754430c0c88f8e7f0d8af   \n",
       "3  7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9   \n",
       "4  07588dd5d0252c7abc99b3834a81bf23741ead4b   \n",
       "\n",
       "                                               title   authorId  \\\n",
       "0  Detecting linguistic idiosyncratic interests i...    3188285   \n",
       "1  Bigrams and BiLSTMs Two Neural Networks for Se...    2782720   \n",
       "2  In Factuality: Efficient Integration of Releva...  144748442   \n",
       "3  Variational Graph Autoencoding as Cheap Superv...   46331602   \n",
       "4  LIMIT-BERT : Linguistics Informed Multi-Task BERT   30887404   \n",
       "\n",
       "          authorName                                           abstract  year  \\\n",
       "0  Masoud Rouhizadeh  Children with autism spectrum disorder often e...  2014   \n",
       "1       Yuri Bizzoni  We present and compare two alternative deep ne...  2018   \n",
       "2      Peter Vickers  Visual Question Answering (VQA) methods aim at...  2021   \n",
       "3           Irene Li  Coreference resolution over semantic graphs li...  2022   \n",
       "4         Junru Zhou  In this paper, we present Linguistics Informed...  2019   \n",
       "\n",
       "                venue  \n",
       "0         CLPsych@ACL  \n",
       "1  Fig-Lang@NAACL-HLT  \n",
       "2                 ACL  \n",
       "3                 ACL  \n",
       "4            FINDINGS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json(r'train.json')\n",
    "test = pd.read_json(r'test.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ae83c8-244a-443d-bf0d-7e3c313e19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLEANING\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bdc00c-08b9-457e-994d-cadb71f7359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing punctuation (found on stackoverflow): https://stackoverflow.com/questions/39782418/remove-punctuations-in-pandas\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e90d45-3e6e-495b-b8fe-5e65e5e4a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd9f127-c69f-4a4d-b906-78c2dbf06110",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"abstract\"] = train['abstract'].apply(remove_punctuations)\n",
    "\n",
    "test[\"abstract\"] = test['abstract'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a754b4-fa7b-47ad-9e97-6583db1f4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Abstract to lowercase \n",
    "train[\"abstract\"] = train['abstract'].str.lower()\n",
    "\n",
    "test[\"abstract\"] = test['abstract'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6554aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING (https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/)\n",
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = re.split('\\s+',text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f32da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying function to the abstract column\n",
    "train[\"abstract\"] = train['abstract'].apply(lambda x: tokenization(x))\n",
    "\n",
    "test[\"abstract\"] = test['abstract'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2cf17fa-bada-4a7d-865a-b7ed337cbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f8c922-6b07-460a-bc68-55c7d2bca710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing nlp library\n",
    "import nltk\n",
    "#Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91294e0d-b813-4d83-a4d7-0c21ad50d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function for stopword removal (https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/)\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b3e173-0671-47d7-bd5e-ca42c0de3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"abstract\"] = train['abstract'].apply(lambda x:remove_stopwords(x))\n",
    "\n",
    "test[\"abstract\"] = test['abstract'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22bf152c-41d2-4531-a701-d921df0b8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LEMMATIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd2fece-9d0a-4435-ad4f-10831904a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3e25b7e-fc65-4ed0-bd1e-6f8634f77958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/dimo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d496bb-0507-4197-a419-bbf05bed6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function for lemmatization (https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/)\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "382d31a7-946c-4973-bdb3-8813bca27947",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['abstract']=train['abstract'].apply(lambda x:lemmatizer(x))\n",
    "\n",
    "test['abstract']=test['abstract'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd100157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>authorId</th>\n",
       "      <th>authorName</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b341b6938308a6d5f47edf490f6e46eae3835fa</td>\n",
       "      <td>Detecting linguistic idiosyncratic interests i...</td>\n",
       "      <td>3188285</td>\n",
       "      <td>Masoud Rouhizadeh</td>\n",
       "      <td>[child, autism, spectrum, disorder, often, exh...</td>\n",
       "      <td>2014</td>\n",
       "      <td>CLPsych@ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c682727ee058aadbe9dbf838dcb036322818f588</td>\n",
       "      <td>Bigrams and BiLSTMs Two Neural Networks for Se...</td>\n",
       "      <td>2782720</td>\n",
       "      <td>Yuri Bizzoni</td>\n",
       "      <td>[present, compare, two, alternative, deep, neu...</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fig-Lang@NAACL-HLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f9b5b32229a7245e43754430c0c88f8e7f0d8af</td>\n",
       "      <td>In Factuality: Efficient Integration of Releva...</td>\n",
       "      <td>144748442</td>\n",
       "      <td>Peter Vickers</td>\n",
       "      <td>[visual, question, answering, vqa, method, aim...</td>\n",
       "      <td>2021</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9</td>\n",
       "      <td>Variational Graph Autoencoding as Cheap Superv...</td>\n",
       "      <td>46331602</td>\n",
       "      <td>Irene Li</td>\n",
       "      <td>[coreference, resolution, semantic, graph, lik...</td>\n",
       "      <td>2022</td>\n",
       "      <td>ACL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07588dd5d0252c7abc99b3834a81bf23741ead4b</td>\n",
       "      <td>LIMIT-BERT : Linguistics Informed Multi-Task BERT</td>\n",
       "      <td>30887404</td>\n",
       "      <td>Junru Zhou</td>\n",
       "      <td>[paper, present, linguistics, informed, multit...</td>\n",
       "      <td>2019</td>\n",
       "      <td>FINDINGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  0b341b6938308a6d5f47edf490f6e46eae3835fa   \n",
       "1  c682727ee058aadbe9dbf838dcb036322818f588   \n",
       "2  0f9b5b32229a7245e43754430c0c88f8e7f0d8af   \n",
       "3  7e8b4cfdc03b59ece2d6b33a217f0abd47f708d9   \n",
       "4  07588dd5d0252c7abc99b3834a81bf23741ead4b   \n",
       "\n",
       "                                               title   authorId  \\\n",
       "0  Detecting linguistic idiosyncratic interests i...    3188285   \n",
       "1  Bigrams and BiLSTMs Two Neural Networks for Se...    2782720   \n",
       "2  In Factuality: Efficient Integration of Releva...  144748442   \n",
       "3  Variational Graph Autoencoding as Cheap Superv...   46331602   \n",
       "4  LIMIT-BERT : Linguistics Informed Multi-Task BERT   30887404   \n",
       "\n",
       "          authorName                                           abstract  year  \\\n",
       "0  Masoud Rouhizadeh  [child, autism, spectrum, disorder, often, exh...  2014   \n",
       "1       Yuri Bizzoni  [present, compare, two, alternative, deep, neu...  2018   \n",
       "2      Peter Vickers  [visual, question, answering, vqa, method, aim...  2021   \n",
       "3           Irene Li  [coreference, resolution, semantic, graph, lik...  2022   \n",
       "4         Junru Zhou  [paper, present, linguistics, informed, multit...  2019   \n",
       "\n",
       "                venue  \n",
       "0         CLPsych@ACL  \n",
       "1  Fig-Lang@NAACL-HLT  \n",
       "2                 ACL  \n",
       "3                 ACL  \n",
       "4            FINDINGS  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e68c9721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstract = train['abstract']\n",
    "test_abstract = test['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b8a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abstract = pd.Series(train_abstract, dtype = \"string\")\n",
    "test_abstract = pd.Series(test_abstract, dtype = \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f39c6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ['child', 'autism', 'spectrum', 'disorder', 'o...\n",
       "1        ['present', 'compare', 'two', 'alternative', '...\n",
       "2        ['visual', 'question', 'answering', 'vqa', 'me...\n",
       "3        ['coreference', 'resolution', 'semantic', 'gra...\n",
       "4        ['paper', 'present', 'linguistics', 'informed'...\n",
       "                               ...                        \n",
       "12124    ['defacto', 'standard', 'decoding', 'method', ...\n",
       "12125    ['report', 'method', 'used', 'result', 'obtain...\n",
       "12126    ['describe', 'second', 'iwpt', 'task', 'endtoe...\n",
       "12127    ['abstract', 'paper', 'investigates', 'ability...\n",
       "12128    ['framenet', 'best', 'currently', 'operational...\n",
       "Name: abstract, Length: 12129, dtype: string"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862e7c88-51b4-4bb2-8ebb-21ba7f913ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94caecb8-a728-4edb-9291-e4390cee4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd12e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_train = vectorizer.fit_transform(train_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bb2d7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12129x60647 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1108974 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24320feb-e866-45aa-9a10-c5d9dd62a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_test = vectorizer.transform(test_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c90e63c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ngrams_test = pd.DataFrame(ngrams_test.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c35d0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10916, 60647) (1213, 60647) (10916,) (1213,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the training set to training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ngrams_train\n",
    "y = train['authorId']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaca2bd-8bc1-4fff-afbb-0f3f664c4f1c",
   "metadata": {},
   "source": [
    "## Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99ad531f-41e2-46af-8fad-2edd5323acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "# instantiating the model with Complement Naive Bayes..\n",
    "model = ComplementNB()\n",
    "# training the model...\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a57cd664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Naive Bayes accuracy on validation set:\n",
      "8.74 %\n"
     ]
    }
   ],
   "source": [
    "print('Complement Naive Bayes accuracy on validation set:')\n",
    "print(round((model.score(X_val, y_val)*100) ,2) , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c022d-d86f-4da3-9651-b01c0c2749b2",
   "metadata": {},
   "source": [
    "## SGD classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d779e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgdc = SGDClassifier(loss = \"log\")\n",
    "sgd_model = sgdc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37955d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent Classifier accuracy on validation set:\n",
      "6.02 %\n"
     ]
    }
   ],
   "source": [
    "print('Stochastic Gradient Descent Classifier accuracy on validation set:')\n",
    "print(round((sgd_model.score(X_val, y_val)*100) ,2) , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ab4b0",
   "metadata": {},
   "source": [
    "## KNeighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "710870f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh = neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "698f8d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier accuracy on validation set:\n",
      "0.99 %\n"
     ]
    }
   ],
   "source": [
    "print('KNeighbors Classifier accuracy on validation set:')\n",
    "print(round((neigh.score(X_val, y_val)*100) ,2) , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27844ce4",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29fc3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb = mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa966325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes accuracy on validation set:\n",
      "0.49 %\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes accuracy on validation set:')\n",
    "print(round((mnb.score(X_val, y_val)*100) ,2) , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c5ec1",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07a4e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC()\n",
    "svc = svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88085b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC accuracy on validation set:\n",
      "11.13 %\n"
     ]
    }
   ],
   "source": [
    "print('Linear SVC accuracy on validation set:')\n",
    "print(round((svc.score(X_val, y_val)*100) ,2) , '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a00ec63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc_largeC = LinearSVC(C = 7)\n",
    "svc_largeC = svc_largeC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daa283bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with higher regularization parameter value accuracy on validation set:\n",
      "11.21 %\n"
     ]
    }
   ],
   "source": [
    "print('Linear SVC with higher regularization parameter value accuracy on validation set:')\n",
    "print(round((svc_largeC.score(X_val, y_val)*100) ,2) , '%')\n",
    "\n",
    "# Higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d366ea",
   "metadata": {},
   "source": [
    "## Training the best fitting model on the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd1e56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svc = LinearSVC(C = 7)\n",
    "svc = svc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae9b239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LinearSVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1785372925 2064493724    2011442    1900163 2056582888    1703046\n",
      "   23181472    2790926  144130537    9120873]\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test\n",
    "y_pred = svc.predict(ngrams_test)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4955be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing type for the dictionary\n",
    "y_pred = y_pred.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1baf3",
   "metadata": {},
   "source": [
    "## Creating a dictionary, matching the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50bd8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting paperId and authorId for ngrams_test\n",
    "ngrams_test['authorId'] = y_pred.tolist()\n",
    "ngrams_test['paperId'] = test['paperId']\n",
    "predictions = ngrams_test[['paperId', 'authorId']]\n",
    "\n",
    "# Creating a list of dictionaries for each row\n",
    "predictions = predictions.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "409cd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predictions as a JSON file (https://stackabuse.com/saving-text-json-and-csv-to-a-file-in-python/)\n",
    "import json\n",
    "\n",
    "with open('predictions.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(predictions, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
